---
title: 'S&DS363 Final Project'
author: "Yavuz Ramiz Ã‡olak, Ryo Tamaki, Liana Wang, David Lieberman"
date: "March 10th, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
rm(list=ls())
options(warn=-1)
library(ggplot2)
library(ggfortify)
library(cowplot)
library(tidyr)
library(MASS)
library(corrplot)
library(mvtnorm)
library(ellipse)
library(data.table)
library(biotools)
library(DiscriMiner)
library(klaR)
```

```{r, include=FALSE}
data <- read.csv("https://pastebin.com/raw/Xzp5dCLG")
working_data <- data
working_data <- data[- as.vector(which(data$Sector %in% c("Financials", "Telecommunications Services"))),]
working_data <- working_data[,-c(3,5,9,11,15,19,20,22)]
setattr(working_data, "row.names", as.vector(working_data$Ticker.Symbol))
data_numeric <- working_data[,-c(1,2,21)]
```

## Introduction, Design and Primary Questions

### PLEASE EDIT MY WRITING HERE -- ADD TO THE INTRO, MY KNOWLEDGE OF ECON IS LIMITED
Our dataset follows 216 stocks on New York Stock Exchange with 21 different variables quantifying their performance on the S&P 500 between the market open on 2015-01-01 and the market close on 2015-12-31 (obtained from Kaggle). Each row contains the metrics for a given a company, with column metrics ranging from Earnings and Total Costs, to Profit Marging and Price/Earnings ratio. **This report intends to identify various paterns within the data:** In particular, we will use the following statistical techniques:

--Which performance metrics tend to vary greatly between stocks? Principal Component Analysis will yield a few uncorrelated principal components in the directions of greatest variance. This will allow us to see which performance metrics tend to correlate with one another (their weights within principal components), and reduce the dimensionality and correlation overall to a few "super variables" to be used in later analysis.

--Are there particular performance metrics that can be used to decern which Sector a stock belongs to? Discriminant Analysis will allow us to identify which principal components are best for discriminating between Sectors (ie. Do stocks in the Energy Sector normally have greater Total Assets than other Sectors), and create discriminator functions that can predict the Sector classification of an unknown stock given its performance metrics.

--THIRD THING

### PLEASE TALK MORE ABOUT WHAT ECON VARIABLES MEAN
## Data

Our dataset has:

--Categorical Variables (3): Ticker Symbol, Sector, Returns

--Discrete Variables (2): Current Ratio, Quick Ratio

--Continuous Variables (16): Capital Expenditures, Cash and Cash Equivalents, Depreciation, Gross Profit, Investments, Liabilities, Long Term Debt, Net Cash Flow, Net Income, Operating Income, Total Assets, Total Equity, Total Liabilities, Earnings Per Share, Estimated Shares Outstanding, Wide Percent Change

```{r}
QQPlot <- function(x, na.rm = TRUE){
  plots <- list()
  j <- 1
  for (i in names(x)) {
    plots[[i]] <- ggplot(x, aes_string(sample = i)) + stat_qq() + stat_qq_line() + xlab(names(x)[j]) + ylab("")
    j <- j+1
  }
  print(plot_grid(plotlist = plots[1:8]))
  print(plot_grid(plotlist = plots[9:16]))
  print(plot_grid(plotlist = plots[17:20]))
}
```

First, let's take a look at the data and make quantile-quantile plots for each performance metric to see if each variable is approximately univariate Normal.
```{r}
working_data[,1:6]
QQPlot(data_numeric)
```

Several of these variables seem to deviate substantially from univariate Normality. Applying a log transformation will likely help. There are several subtleties. Many variables take on negative values, so to remedy this, I will first shift the data by the magnitude of the smallest value + 1 before taking its log. However, this addition disrupts ratio quantities. Thus, in the case of Earnings Per Share which contained negative values, we first take the absolute value, then apply the log transformation. Wide Percent Change already seemed approximately univariate Normal (approximately a straight line quantile-quantile plot), so it was not transformed.

### ASK JRDS ABOUT THESE TRANSFORMATIONS
```{r, echo = TRUE}
data_transformed <- data_numeric

data_transformed$Capital.Expenditures <- log(data_transformed$Capital.Expenditures + abs(min(data_transformed$Capital.Expenditures)) + 1)
data_transformed$Cash.and.Cash.Equivalents <- log(data_transformed$Cash.and.Cash.Equivalents)
data_transformed$Current.Ratio <- log(data_transformed$Current.Ratio)
data_transformed$Depreciation <- log(data_transformed$Depreciation + abs(min(data_transformed$Depreciation)) + 1)
data_transformed$Gross.Profit <- log(data_transformed$Gross.Profit + abs(min(data_transformed$Gross.Profit)) + 1)
data_transformed$Investments <- log(data_transformed$Investments + abs(min(data_transformed$Investments)) + 1)
data_transformed$Liabilities <- log(data_transformed$Liabilities + abs(min(data_transformed$Liabilities)) + 1)
data_transformed$Long.Term.Debt <- log(data_transformed$Long.Term.Debt + abs(min(data_transformed$Long.Term.Debt)) + 1)
data_transformed$Net.Cash.Flow <- log(data_transformed$Net.Cash.Flow + abs(min(data_transformed$Net.Cash.Flow)) + 1)
data_transformed$Net.Income <- log(data_transformed$Net.Income + abs(min(data_transformed$Net.Income)) + 1)
data_transformed$Operating.Income <- log(data_transformed$Operating.Income + abs(min(data_transformed$Operating.Income)) + 1)
data_transformed$Quick.Ratio <- log(data_transformed$Quick.Ratio)
data_transformed$Total.Assets <- log(data_transformed$Total.Assets)
data_transformed$Total.Equity <- log(data_transformed$Total.Equity + abs(min(data_transformed$Total.Equity)) + 1)
data_transformed$Total.Liabilities <- log(data_transformed$Total.Liabilities + abs(min(data_transformed$Total.Liabilities)) + 1)
data_transformed$Earnings.Per.Share <- log(abs(data_transformed$Earnings.Per.Share))
colnames(data_transformed)[colnames(data_transformed)=="Earnings.Per.Share"] <- "Abs.Earnings.Per.Share"
data_transformed$Estimated.Shares.Outstanding <- log(data_transformed$Estimated.Shares.Outstanding)
data_transformed$wide.percent_change <- data_transformed$wide.percent_change

data_transformed <- as.data.frame(data_transformed)
```


```{r}
QQPlot(data_transformed)
```

After log transforming the data, the variables all appear to be approximately univariate Normal (save for a few pesky outliers).

```{r}
CSQPlot<-function(vars,label="Chi-Square Quantile Plot"){
   #usually, vars is xxx$residuals or data from one group and label is for plot
     x<-cov(scale(vars),use="pairwise.complete.obs")
     squares<-sort(diag(as.matrix(scale(vars))%*%solve(x, tol=1e-20)%*%as.matrix(t(scale(vars)))))
     quantiles<-quantile(squares)
     hspr<-quantiles[4]-quantiles[2]
     cumprob<-c(1:length(vars[,1]))/length(vars[,1])-1/(2*length(vars[,1]))
     degf<-dim(x)[1]
     quants<-qchisq(cumprob,df=degf)
     gval<-(quants**(-1+degf/2))/(exp(quants/2)*gamma(degf/2)*(sqrt(2)**degf))
     scale<-hspr / (qchisq(.75,degf)-qchisq(.25,degf))
     se<-(scale/gval)*sqrt(cumprob*(1-cumprob)/length(squares))
     lower<-quants-2*se
     upper<-quants+2*se
    plot(quants,squares,col='red',pch=19,cex=1.2,xlab="Chi-Square Quantiles",
     ylab=label,main=paste("Chi-Square Quantiles for",label),ylim=range(upper,lower, squares) , xlim=range(c(0,quants)))
    lines(c(0,100),c(0,100),col=1)
    lines(quants,upper,col="blue",lty=2,lwd=2)
    lines(quants,lower,col="blue",lty=2,lwd=2)
    legend(0,range(upper,lower)[2]*.9,c("Data","95% Conf Limits"),lty=c(0,2),col=c("red","blue"),lwd=c(2,2),
      pch=c(19,NA))
}
```

Now, let's see if our data is approximately multivariate Normal using a chi-square quantile-quantile plot and seeing if the data all fall within the 95% confidence interval boundaries, denoted by the blue dotted lines on the graph below.
```{r}
CSQPlot(data_transformed, label="data_transformed")
```

As we can see, our data is very far from multivariate Normal -- nearly all of the data lie outside the 95% confidence limits on the chi-square quantile-quantile plot.


## Section 1: Principal Components Analysis

Let's construct a correlation matrix for our data. Hopefully, some variables will be highly correlated so our data will be a good match for Principal Component Analysis.
```{r}
correlation_matrix <- setattr(as.data.frame(round(cor(data_transformed), 2)), "row.names", names(data_transformed))
correlation_matrix[,1:6]
```


Now we sort the correlations by largest magnitude and display the first six entries.
```{r}
correlation_vector <- as.vector(as.matrix(correlation_matrix))
correlation_vector <- correlation_vector[-as.vector(which(correlation_vector == 1))]
sorted_correlations <- correlation_vector[order(-abs(correlation_vector))][c(FALSE, TRUE)]
head(sorted_correlations)
```

Nice, we have some highly correlated variables. PCA will work well for our data.



Here's a more graphical representation of the correlation matrix that was created above.
```{r}
correlation_plot <- cor(data_transformed)
for (i in 1:ncol(correlation_plot)){
  correlation_plot[i,i] <- 0
}
corrplot(correlation_plot, method = "color", tl.cex=0.6)
```

```{r}
pc1 <- princomp(data_transformed, cor=TRUE)
pc2 <- prcomp(data_transformed, scale=TRUE)
```

```{r}
print(summary(pc2),digits=2)
pc1$loadings[,1:4]
```

The table above shows that if we want to explain at least 50% of the variance across our data, we should keep the first four principal components, which explain 51.8% of the variance. Looking loading coefficients for the first four principal components (major contributor:= abs(loading coefficient) > 0.3)

## ECON KNOWLEDGE PLEASE

--First Principal Component Major Contributors: Total.Liabilities (-0.491); Total.Assets (-0.487); Estimated.Shares.Outstanding (-0.401); Long.Term.Debt (-0.304)

*It seems that all of these variables deal with ...* 


--Second Principal Component Major Contributors: Quick.Ratio (-0.520); Current.Ratio (-0.517); Cash.and.Cash.Equivalents (-0.382); Operating.Income (0.360); Net.Income (0.358)

*It seems that all of these variables deal with ...* 

--Third Principal Component Major Contributors: Net.Income (-0.556); Operating.Income (-0.556)

*It seems that all of these variables deal with ...* 

--Fourth Principal Component Major Contributors: Wide.Percent_Change (0.618); Gross.Profit (0.443); Net.Cash.Flow (0.367); Total.Equity (-0.327)

*It seems that all of these variables deal with ...* 


I would need to use the first three components (Comp1, Comp2, and Comp3), which explain approximately 94.7% of the total variance. Notably, only the eigenvalue for Comp1 is greater than 1; however, if I wanted to be conservative and explain at least 95% of the variation, I could use Comp1-4. The scree plot shown in Figure 2 below reiterates that the great majority of the total variance in my data is explained by Comp1. Comp5 and Comp6 do not contribute much additional information.


According to the screeplot, we would cut above the first "elbow," which in this case would mean we would only keep the first principal component. However, we chose to 
```{r}
screeplot(pc2,type="lines",col="red",lwd=2,pch=19,cex=1.2,main="Scree Plot of Raw Drug Data")
```

```{r}
biplot(pc2,choices=c(1,2),pc.biplot=T)
biplot(pc2,choices=c(1,3),pc.biplot=T)
```

```{r}
varimax3 <- varimax(pc2$rotation[,1:3])
PCA_Data <- scale(as.matrix(data_transformed)) %*% varimax3$loadings
PCA_Data <- as.data.frame(PCA_Data)

Sectors <- as.vector(working_data$Sector)

PCA_Data <- cbind(Sectors, PCA_Data)
```

```{r}
par(mar=c(2,15,2,2))
boxplot(PC1 ~ Sectors, data=PCA_Data, horizontal = T, main="PC1 by Industry", las=2)
boxplot(PC2 ~ Sectors, data=PCA_Data, horizontal = T, main="PC2 by Industry", las=2)
boxplot(PC3 ~ Sectors, data=PCA_Data, horizontal = T, main="PC3 by Industry", las=2)
```

```{r}
PC1_outliers <- as.vector(which(PCA_Data$PC1 %in% as.vector(boxplot.stats(PCA_Data$PC1)$out)))
PC2_outliers <- as.vector(which(PCA_Data$PC2 %in% as.vector(boxplot.stats(PCA_Data$PC2)$out)))
PC3_outliers <- as.vector(which(PCA_Data$PC3 %in% as.vector(boxplot.stats(PCA_Data$PC3)$out)))
PCA_Data <- PCA_Data[-c(PC1_outliers,PC2_outliers,PC3_outliers),]
data_transformed <- data_transformed[-c(PC1_outliers,PC2_outliers,PC3_outliers),]
Sectors <- Sectors[-c(PC1_outliers,PC2_outliers,PC3_outliers)]
```

```{r}
par(mar=c(2,15,2,2))
boxplot(PC1 ~ Sectors, data=PCA_Data, horizontal = T, main="PC1 by Industry", las=2)
boxplot(PC2 ~ Sectors, data=PCA_Data, horizontal = T, main="PC2 by Industry", las=2)
boxplot(PC3 ~ Sectors, data=PCA_Data, horizontal = T, main="PC3 by Industry", las=2)
```


```{r}
for (name in unique(Sectors)){
  print(paste("Covariance Matrix for", name))
  print(cov(PCA_Data[PCA_Data$Sector == name, 2:4]))
  cat(c("log-determinant", log(det(cov(PCA_Data[PCA_Data$Sector == name, 2:4]))), "\n\n"))
}

boxM(PCA_Data[,c("PC1","PC2","PC3")], PCA_Data$Sector)
```

```{r}
for (name in unique(Sectors)){
  CSQPlot(PCA_Data[which(Sectors==name),][-1], label=name)
}
```