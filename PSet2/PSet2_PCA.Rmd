---
title: "SDS363 Problem Set 2"
author: "Liana Wang, Yavuz Ramiz Çolak, Ryo Tamaki, David Lieberman"
date: "2/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(ggplot2)
library(cowplot)
library(tidyr)
library(corrplot)
library(mvtnorm) # References rmvnorm()
library(ellipse) # References ellipse()
library(ggfortify)
```

## PROBLEM 1
1). First, discuss whether your data seems to have a multivariate normal distribution. Make univariate plots (boxplots, normal quantile plots as appropriate). Then make transformations as appropriate. You do NOT need to turn all this in, but describe what you did. THEN make a chi-square quantile plot of the data. Turn in your chi-square quantile plot as appropriate and comment on what you see. NOTE that multivariate normality is NOT a requirement for PCA to work!

```{r}
data <- read.csv("https://pastebin.com/raw/z6pgskch")
data <- data %>% drop_na()

boxplot(data)

data_transformed <- data
data_transformed$regret <- log(data$regret)
data_transformed$notuse <- log(data$notuse)
data_transformed$psycho <- sign(data$psycho)*sqrt(abs(data$psycho))
data_transformed$stoned <- log(data$stoned)
data_transformed$noaspirin <- sqrt(data$noaspirin)
data_transformed$relationship <- sqrt(data$relationship)
data_transformed$lessalcohol <- log(data$lessalcohol)

boxplot(data_transformed)

QQPlot <- function(x, na.rm = TRUE){
  plots <- list()
  j <- 1
  for (i in names(x)) {
    plots[[i]] <- ggplot(x, aes_string(sample = i)) + stat_qq() + stat_qq_line() + xlab(names(x)[j]) + ylab("")
    j <- j+1
  }
  plot_grid(plotlist = plots)
}

QQPlot(data_transformed)
```

*We first created a boxplot of our data. There is a pretty significant skew on a few of the variables, which we tried to correct through log and square root transformations. After the transformation, we re-created the boxplots. We observed that all variables were distributed more symmetrically and were closer to normal. Furthermore, after transformation, our resulting QQ-plots appeared to fall mostly along the line that would indicate a roughly normal relationship. It is important to note that while some of our QQ plots were partially piece-wise, that was mainly because we included discrete variables. Discrete variables are relevant for our analysis, so we still wanted to include them. Also, our data set is relatively small. With more data points, the QQplots would more closely follow the 45 degree line.*

```{r}
CSQPlot<-function(vars,label="Chi-Square Quantile Plot"){
   #usually, vars is xxx$residuals or data from one group and label is for plot
     x<-cov(scale(vars),use="pairwise.complete.obs")
     squares<-sort(diag(as.matrix(scale(vars))%*%solve(x)%*%as.matrix(t(scale(vars)))))
     quantiles<-quantile(squares)
     hspr<-quantiles[4]-quantiles[2]
     cumprob<-c(1:length(vars[,1]))/length(vars[,1])-1/(2*length(vars[,1]))
     degf<-dim(x)[1]
     quants<-qchisq(cumprob,df=degf)
     gval<-(quants**(-1+degf/2))/(exp(quants/2)*gamma(degf/2)*(sqrt(2)**degf))
     scale<-hspr / (qchisq(.75,degf)-qchisq(.25,degf))
     se<-(scale/gval)*sqrt(cumprob*(1-cumprob)/length(squares))
     lower<-quants-2*se
     upper<-quants+2*se
    plot(quants,squares,col='red',pch=19,cex=1.2,xlab="Chi-Square Quantiles",
     ylab=label,main=paste("Chi-Square Quantiles for",label),ylim=range(upper,lower, squares) , xlim=range(c(0,quants)))
    lines(c(0,100),c(0,100),col=1)
    lines(quants,upper,col="blue",lty=2,lwd=2)
    lines(quants,lower,col="blue",lty=2,lwd=2)
    legend(0,range(upper,lower)[2]*.9,c("Data","95% Conf Limits"),lty=c(0,2),col=c("red","blue"),lwd=c(2,2),
      pch=c(19,NA))
}
CSQPlot(data_transformed,label="Drug Attitudes")
```

*Our CSQ plot seems to indicate a roughly normal multivariate distribution, with all data (except for 1 variable, it appears) falling within the 95% confidence interval and a good number of variables falling along the line which indicates normality. The relative skew is, as noted above, likely partially due to the small sample size.*

## PROBLEM 2
2). Compute the correlation matrix between all variables. Comment on relationships you do/do not observe. Do you think PCA will work well?

```{r}
round(cor(data_transformed), 2)
#version 1
corrplot(cor(data_transformed), method = "color")
#version 2
corrplot.mixed(cor(data_transformed), lower.col="black", upper = "ellipse", tl.col = "black", number.cex=.7, order = "hclust",tl.pos = "lt", tl.cex=.7)
```
*The correlation plot shows that while there is low correlation between many of  the variables, there are a few spots where variables are moderately or highly correlated. This includes, for example, "notuse" and "relationship"; "trip" and "legal"; "dope" and "notuse," as well as "fun" and "drugscene." Given the noted highly correlated variables, PCA will be helpful in reducing dimensions. It won't necessarily give us two or three highly explanatory variables that sum up the entire dataset, but it will reduce the repetitiveness of current variables and allow us to group them somewhat intelligently.* 

## PROBLEM 3
3). Perform Principle components analysis using the Correlation matrix (standardized variables). Think about how many principle components to retain. To make this decision look at
 Total variance explained by a given number of principle components
 The ‘eigenvalue > 1’ criteria
 The ‘scree plot elbow’ method (turn in the scree plot)
 Parallel Analysis : think about whether this is appropriate based on what you
discover in question 1.

```{r}
source("http://www.reuningscherer.net/STAT660/R/parallel.r.txt")
source("http://reuningscherer.net/stat660/r/ciscoreplot.R.txt")
data2 <- data_transformed[,c(names(data_transformed))]
pc1 <- princomp(data2, cor=TRUE)

#To see the cumulative variability accounted for by our components
print(summary(pc1),digits=2,loadings=pc1$loadings,cutoff=0)
round(pc1$sdev^2,2)

#We also want to check a screeplot in order to identify any "elbows": 
screeplot(pc1,type="lines",col="red",lwd=2,pch=19,cex=1.2,main="Scree Plot of Raw Drug Data")
```

*Recall that Parallel Analysis is appropriate if the data has a multivariate normal distribution. Based on our previous results from (1), in particular the Chi-Squared Quantile plot, we note that our data appears to have a multivariate normal distribution –– all data points (except for 2) are between the 95% confidence interval bounds with respect to the 45-degree line. Consequently, we would say that our data is appropriate for Parallel Analysis, given their multivariate normality.*

```{r}
source("http://www.reuningscherer.net/STAT660/R/parallel.r.txt")
parallelplot(pc1)
```

*Following our analysis, we decided to retain 3 principal components. First, when we look at the summary of our PCA, we see that by including components 1,2 and 3, we are able to explain 50% of the variability, which is strong given that we are only including three components. Furthermore, following the eigenvalue rule of thumb, we see that the first three components have eigenvalues that are greater than 1 (in fact, much above 2), and the eigenvalues components beyond 3rd rapidly fall near and below 1. The scree plot shows potential "elbows" at the 2nd and 5th component; while the 3rd component falls beyond the elbow at the 2nd component, we believe the third component's high eigenvalues and ability to explain more variability merits inclusion (as well as the makeup of its set of contributors, discussed below in problem 4.) As such, including the 3rd component in our judgment seems like the best way of maximizing explanatory power while minimizing the number of components to include.*


## PROBLEM 4
4). For principle components you decide to retain, examine the loadings (principle components) and think about an interpretation for each retained component if possible.

```{r}
unclass(pc1$loadings)[,1:3]
```
*Note that following our interpretation of the scree plot with parallel analysis thresholds, we decided to retain the first 3 principal components.*

*In the first principal component, we see that 'notuse' is the primary contributor, with 'relationship,' and 'drugscene'. The questions which produced these variables are here:* 
    'notuse': Even if my best friend gave me some hash, I probably wouldn't use it.
    'relationship': If people use drugs together, their relationships will be improved.
    'drugscene': In spite of what the establishment says, the drug scene is really "where it's at".
*It seems that all of these variables speak to the social aspect of drug usage and people's attitudes around it as a social activity. People who like the drug scene probably would likely use drugs provided by their best friend would probably also respond that it improves relationships.* 


*The second principal component's (Comp.2) primary contributors include 'noaspirin,' 'legal,' 'dangerous,' and 'calm.'*
    'noaspirin': I'd have to be pretty sick before I'd take any drug including an aspirin.
    'legal': All drugs should be made legal and freely available.
    'dangerous': As a general rule of thumb, most drugs are dangerous and should be used only with medical authorization.
    'calm': I wish I could get hold of some pills to calm me down whenever I get "up tight".
*The common thread between these variables seems to be that the questions have a semi-medical, individualized nature (with the exception of 'legal') to their inquiry that would lead to high correlations between answers (even if that correlation is highly negative). For example, someone who is very suspicious of taking aspirin would probably highly agree that most drugs are dangerous and would highly disagree that taking pills is a legitimate way to calm down. In that case, they might also extrapolate their personal experience with drug usage to others (reflected in 'legal') in the belief that they are not medically helpful. Those who who think that drugs are key to feeling better and have individual experience using them in a semi-medical way would likely also want them legal and freely available as a medical recourse for others.* 
    

*The third principal component's (Comp.3) primary contributors are 'side effects' and 'experience.'*
    'sideeffects': Students should be told about the harmful side effects of certain drugs.
    'experience': People who make drug legislation should really have personal experience with drugs.
*It makes sense that these responses would be correlated and form a component since they all reflect something about the respondent's attitudes towards regulations and other people's drug usage--especially young people. Those who think students should know about hamful side effects might want legislators who are drug-free (if they see it as a moral issue), or might really want legislators with personal experience, especially if that experience is negative. Either way, it reflects a concern about drug use in society at-large.* 

## PROBLEM 5
5) Make a score plot of the scores for at least one pair of component scores (one and two, one and three, two and three, etc). Discuss any trends/groupings you observe (probably, this will be ‘none’). As a bonus, try to make a 95% Confidence Ellipse for two of your components. You might want to also try making a bi-plot if you’re using R.

Define the Score Plot Function
```{r}
ciscoreplot<-function(x,comps,namevec){
  y1<-sqrt(5.99*(x$sdev[comps[1]]^2))
  ymod<-y1-y1%%.05
  y1vec<-c(-y1,seq(-ymod,ymod,by=0.05),y1)
  y2vecpos<-sqrt((5.99-(y1vec^2)/x$sdev[comps[1]]^2)*x$sdev[comps[2]]^2)
  y2vecneg<--sqrt((5.99-(y1vec^2)/x$sdev[comps[1]]^2)*x$sdev[comps[2]]^2)
  y2vecpos[1]<-0
  y2vecneg[1]<-0
  y2vecpos[length(y2vecpos)]<-0
  y2vecneg[length(y2vecneg)]<-0
  plot(x$scores[,comps[1]],x$scores[,comps[2]],pch=19,cex=1.2,ylim=c(min(y2vecneg,x$scores[,comps[2]]),max(y2vecpos,x$scores[,comps[2]])),
    main="PC Score Plot", xlab=paste("Scores for PC",comps[1],sep=" "), ylab=paste("Scores for PC",comps[2],sep=" "),
    xlim=c(min(y1vec,x$scores[,comps[1]]),max(y1vec,x$scores[,comps[1]])))
    lines(y1vec,y2vecpos,col="Red",lwd=2)
    lines(y1vec,y2vecneg,col="Red",lwd=2)
  outliers<-((x$scores[,comps[1]]^2)/(x$sdev[comps[1]]^2)+(x$scores[,comps[2]]^2)/(x$sdev[comps[2]]^2))>5.99
  points(x$scores[outliers,comps[1]],x$scores[outliers,comps[2]],pch=19,cex=1.2,col="Blue")
  text(x$scores[outliers,comps[1]],x$scores[outliers,comps[2]],col="Blue",lab=namevec[outliers], pos=4)
}
```
Let's make the scoreplot for the first two components, including a 95% confidence ellipse in the process:
```{r}
ciscoreplot(pc1,c(1,2), names(data))
```
*We see a potential grouping: some on the right and some on the left. But the grouping does not look too strong. We also observe 2 outliers: the variables calm and experience.* 

```{r}
biplot(pc1,choices=c(1,2),pc.biplot=T)
```

## PROBLEM 6
6). Write a paragraph summarizing your findings, and your opinions about the effectiveness of using principle components on this data. Include evidence based on scatterplots of linearity in higher dimensional space, note any multivariate outliers in your score plot, comment on sample size relative to number of variables, etc.

*From the biplot and scoreplot above, we see that there are not any super apparent groupings of variables that would lead to highly explanatory principal components: in the scoreplot, the dots are fairly scattered, while in the biplot, the vectors point in all directions. This makes sense given our earlier commentary after seeing the correlation plot, where only a few pairs (potentially triplets) of variables seemed to be highly correlated and many others had low to moderate correlation.* 

*Part of this may be due to our sample size - note that we only have 38 (relatively few) observations for 20 (relatively many) variables, which makes it very difficult to even see the distribution of responses per variable, let alone determine very rigorous multivariate relationships. While we have outliers with 'calm' and 'experience' according to the scoreplot alone, it may be due simply to the lack of many responses.* 

*Although we did select three principal components above which reflected the social, medical/individual needs, and society/regulatory-oriented attitudes toward drug usage, and they did explain approximately half the variability of the data, PCA might not be the most effective way to make sense of this data especially since each component included multiple contributors with approximately the same weight of contribution. Perhaps with more observations to the data set, or a more normally distributed set of responses, we could derive more strongly explanatory principal components from the dataset. Given the current state of the data, however, PCA was helpful in reducing the dimensions of the dataset and grouping some variables into these three categories of social, medical/individual and society/regulatory, which made people's responses to drug attitudes slightly easier to understand and provided us some insight into the factors that might affect someone's drug attitudes or different categories in which a respondent might think about drug usage which we did not have before.* 


